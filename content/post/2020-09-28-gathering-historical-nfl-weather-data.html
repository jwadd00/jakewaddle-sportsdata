---
title: Gathering Historical NFL Weather Data
author: Jake Waddle
date: '2020-09-28'
slug: gathering-historical-nfl-weather-data
categories:
  - R
tags:
  - NFL
  - Weather
  - Fantasy
description: ''
topics: []
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<div id="warmish-welcome" class="section level1">
<h1>Warmish Welcome</h1>
<p>Fantasy sports are a passion of mine because they reside at the intersection of two of my favorite things in the world: sports and data. Over the last 4 or so years, I have built data sets suitable for modeling fantasy football and basketball outcomes. I tend to favor daily fantasy, but weather data is valuable for season long fantasy football as well.</p>
<p>In fantasy football, weather data are valuable for a variety of reasons. Conventional wisdom states temperature, wind, and precipation will affect throwing the football, the kicking game, holding on to the football, etc. After reading through this post, you will have the necessary data to explore these claims.</p>
<div id="setting-up" class="section level2">
<h2>Setting Up</h2>
<p>To start, we’ll load the necessary libraries. From there, we’ll find a website with weather data, write a function to scrape the data and then run that function on several web pages automatically to build a complete historical data set.</p>
<p>The website we will be using is <a href="http://nflweather.com/">NFL Weather</a>. Like most real-world exercises, the data is not presented to us in a perfectly built table. We’ll need to do a fair amount of data wrangling to mold the data into a useable structure.</p>
<pre class="r"><code># package management
library(tidyverse)
library(rvest)
library(janitor)
library(glue)</code></pre>
</div>
</div>
<div id="exploring-nflweather.com" class="section level1">
<h1>Exploring NFLWeather.com</h1>
<p>Once you navigate to <a href="http://nflweather.com/">NFL Weather</a>, you can see the weeks indexed with small blue boxes towards the top, directly in the middle of the page. Clicking on the ‘1’ takes you to the weather for week 1 of the 2020 season. Notice the url for this page: <a href="http://nflweather.com/en/week/2020/week-1/" class="uri">http://nflweather.com/en/week/2020/week-1/</a>. Simply replace ‘2020’ in the url with ‘2019’ will direct you to the week 1 forecast for the 2019 season. As you might have guessed, swapping ‘week-1’ with ‘week-8’ will launch the forecast for week 8. Already, we can see that the forecast for each week of a given season can be accessed by switching the year and week parts of the url.</p>
<p>Let’s start with accessing the weather data for week 1 of the 2020 season. Using rvest, we can quickly scan the html for tables and parse appropriately using the <code>read_html()</code> and <code>html_table()</code> functions. These commands parse the html from the url given and return the tables in a list. Using <code>glimpse()</code>, we see that a list of 1 data frame that has some blank rows and null columns is returned.</p>
<pre class="r"><code>url &lt;- &#39;http://nflweather.com/en/week/2020/week-1/&#39;

url %&gt;% 
  read_html() %&gt;% 
  html_table() %&gt;%
  glimpse()</code></pre>
<pre><code>## List of 1
##  $ :&#39;data.frame&#39;:    16 obs. of  13 variables:
##   ..$                  : logi [1:16] NA NA NA NA NA NA ...
##   ..$ Away             : chr [1:16] &quot;Texans&quot; &quot;Eagles&quot; &quot;Dolphins&quot; &quot;Packers&quot; ...
##   ..$ Game             : logi [1:16] NA NA NA NA NA NA ...
##   ..$ Game             : chr [1:16] &quot;@&quot; &quot;@&quot; &quot;@&quot; &quot;@&quot; ...
##   ..$ Game             : logi [1:16] NA NA NA NA NA NA ...
##   ..$ Home             : chr [1:16] &quot;Chiefs&quot; &quot;Redskins&quot; &quot;Patriots&quot; &quot;Vikings&quot; ...
##   ..$ Time (ET)        : chr [1:16] &quot;Final: 20 - 34&quot; &quot;Final: 17 - 27&quot; &quot;Final: 11 - 21&quot; &quot;Final: 43 - 34&quot; ...
##   ..$ TV               : chr [1:16] &quot;NBC&quot; &quot;FOX&quot; &quot;CBS&quot; &quot;FOX&quot; ...
##   ..$                  : logi [1:16] NA NA NA NA NA NA ...
##   ..$ Forecast         : chr [1:16] &quot;58f Overcast&quot; &quot;76f Partly Cloudy&quot; &quot;73f Clear&quot; &quot;DOME&quot; ...
##   ..$ Extended Forecast: chr [1:16] &quot;Overcast. Rain in the morning and afternoon.&quot; &quot;Partly Cloudy. Clear throughout the day.&quot; &quot;Clear. Partly cloudy throughout the day.&quot; &quot;Clear. Clear throughout the day.&quot; ...
##   ..$ Wind             : chr [1:16] &quot;6m NNE&quot; &quot;4m S&quot; &quot;6m S&quot; &quot;2m SW&quot; ...
##   ..$                  : chr [1:16] &quot;Details&quot; &quot;Details&quot; &quot;Details&quot; &quot;Details&quot; ...</code></pre>
<div id="data-wrangling" class="section level2">
<h2>Data Wrangling</h2>
<p>We’ve returned the data frame we want, but definitely not the data frame we need. The initial output requires additional work.</p>
<p>We’ll use <code>clean_names()</code> from the <code>janitor</code> package to give each column a nice, clean name.</p>
<pre class="r"><code>url %&gt;% 
  read_html() %&gt;% 
  html_table() %&gt;%
  .[[1]] %&gt;%  # select the first and only element in the list 
  clean_names() %&gt;%
  glimpse()</code></pre>
<pre><code>## Rows: 16
## Columns: 13
## $ x                 &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N...
## $ away              &lt;chr&gt; &quot;Texans&quot;, &quot;Eagles&quot;, &quot;Dolphins&quot;, &quot;Packers&quot;, &quot;Colts...
## $ game              &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N...
## $ game_2            &lt;chr&gt; &quot;@&quot;, &quot;@&quot;, &quot;@&quot;, &quot;@&quot;, &quot;@&quot;, &quot;@&quot;, &quot;@&quot;, &quot;@&quot;, &quot;@&quot;, &quot;@&quot;,...
## $ game_3            &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N...
## $ home              &lt;chr&gt; &quot;Chiefs&quot;, &quot;Redskins&quot;, &quot;Patriots&quot;, &quot;Vikings&quot;, &quot;Jag...
## $ time_et           &lt;chr&gt; &quot;Final: 20 - 34&quot;, &quot;Final: 17 - 27&quot;, &quot;Final: 11 - ...
## $ tv                &lt;chr&gt; &quot;NBC&quot;, &quot;FOX&quot;, &quot;CBS&quot;, &quot;FOX&quot;, &quot;CBS&quot;, &quot;FOX&quot;, &quot;CBS&quot;, ...
## $ x_2               &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N...
## $ forecast          &lt;chr&gt; &quot;58f Overcast&quot;, &quot;76f Partly Cloudy&quot;, &quot;73f Clear&quot;,...
## $ extended_forecast &lt;chr&gt; &quot;Overcast. Rain in the morning and afternoon.&quot;, &quot;...
## $ wind              &lt;chr&gt; &quot;6m NNE&quot;, &quot;4m S&quot;, &quot;6m S&quot;, &quot;2m SW&quot;, &quot;8m ESE&quot;, &quot;11m...
## $ x_3               &lt;chr&gt; &quot;Details&quot;, &quot;Details&quot;, &quot;Details&quot;, &quot;Details&quot;, &quot;Deta...</code></pre>
<p>From there, we’ll select both home and away team columns, the forecast column, and the wind column. The forecast field holds a text description of the weather from which we can parse the temperature and precipiation out of.</p>
<pre class="r"><code>url %&gt;% 
  read_html() %&gt;% 
  html_table() %&gt;%
  .[[1]] %&gt;% 
  clean_names() %&gt;%
  select(away, home, forecast, wind) %&gt;% 
  glimpse()</code></pre>
<pre><code>## Rows: 16
## Columns: 4
## $ away     &lt;chr&gt; &quot;Texans&quot;, &quot;Eagles&quot;, &quot;Dolphins&quot;, &quot;Packers&quot;, &quot;Colts&quot;, &quot;Bears...
## $ home     &lt;chr&gt; &quot;Chiefs&quot;, &quot;Redskins&quot;, &quot;Patriots&quot;, &quot;Vikings&quot;, &quot;Jaguars&quot;, &quot;L...
## $ forecast &lt;chr&gt; &quot;58f Overcast&quot;, &quot;76f Partly Cloudy&quot;, &quot;73f Clear&quot;, &quot;DOME&quot;, ...
## $ wind     &lt;chr&gt; &quot;6m NNE&quot;, &quot;4m S&quot;, &quot;6m S&quot;, &quot;2m SW&quot;, &quot;8m ESE&quot;, &quot;11m W&quot;, &quot;3m ...</code></pre>
</div>
<div id="text-gymnastics" class="section level2">
<h2>Text Gymnastics</h2>
<p>Since the season and week fields are not included in the data, we need to extract them from the url. Remembering back to when we changed the ‘2020’ in the url to ‘2019’, we know that the position of the season portion of the url will not change. Using <code>stringr</code> and <code>str_sub</code>, we’re able to extract characters based on their position within the url - in this case characters 31-34.</p>
<p>Extracting the week out of the url is a little more complex. To start, we use regular expressions to extract all characters of the url following the ‘-’. Using <code>sub()</code>, we actually pattern match all characters prior to and including the ‘-’ and replace with ’’ (nothing). This leaves us with <code>1/</code>. From here, we just need to capture the number to serve as our week column. Here, I go back to <code>str_sub</code> and extract the characters from the right beginning with 3 characters from the right and ending with 2 characters from the right which will capture double digit weeks as well.</p>
<pre class="r"><code>url %&gt;% 
  read_html() %&gt;% 
  html_table() %&gt;%
  .[[1]] %&gt;% 
  clean_names() %&gt;%
  select(away, home, forecast, wind) %&gt;%
  mutate(season = str_sub(url, start= 31, end = 34),
         week = str_sub(gsub(&#39;.*\\-&#39;, &#39;&#39;, url), start = -3, end = -2)) %&gt;% 
  glimpse()</code></pre>
<pre><code>## Rows: 16
## Columns: 6
## $ away     &lt;chr&gt; &quot;Texans&quot;, &quot;Eagles&quot;, &quot;Dolphins&quot;, &quot;Packers&quot;, &quot;Colts&quot;, &quot;Bears...
## $ home     &lt;chr&gt; &quot;Chiefs&quot;, &quot;Redskins&quot;, &quot;Patriots&quot;, &quot;Vikings&quot;, &quot;Jaguars&quot;, &quot;L...
## $ forecast &lt;chr&gt; &quot;58f Overcast&quot;, &quot;76f Partly Cloudy&quot;, &quot;73f Clear&quot;, &quot;DOME&quot;, ...
## $ wind     &lt;chr&gt; &quot;6m NNE&quot;, &quot;4m S&quot;, &quot;6m S&quot;, &quot;2m SW&quot;, &quot;8m ESE&quot;, &quot;11m W&quot;, &quot;3m ...
## $ season   &lt;chr&gt; &quot;2020&quot;, &quot;2020&quot;, &quot;2020&quot;, &quot;2020&quot;, &quot;2020&quot;, &quot;2020&quot;, &quot;2020&quot;, &quot;2...
## $ week     &lt;chr&gt; &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;...</code></pre>
<p>For capturing the wind, we’ll simply remove all characters following and including the lower case ‘m’ in the wind column. This will give us the numerical representation of the wind. Similarly, for temperature we can use the same regular expression for the lower case ‘f’ in the forecast column. The weather column will be generated by removing every character prior to and including the first white space using the forecast column.</p>
<pre class="r"><code>url %&gt;% 
  read_html() %&gt;% 
  html_table() %&gt;%
  .[[1]] %&gt;% 
  clean_names() %&gt;%
  select(away, home, forecast, wind) %&gt;%
  mutate(season = str_sub(url, start= 31, end = 34),
         week = str_sub(gsub(&#39;.*\\-&#39;, &#39;&#39;, url), start = -3, end = -2),
         wind = as.numeric(gsub( &quot;m.*$&quot;, &quot;&quot;,wind)),
         temperature = ifelse(forecast == &#39;DOME&#39;, 71, gsub( &quot;f.*$&quot;, &quot;&quot;, forecast)),
         weather = gsub(&quot;.*? &quot;, &quot;&quot;, forecast)) %&gt;%
  glimpse()</code></pre>
<pre><code>## Rows: 16
## Columns: 8
## $ away        &lt;chr&gt; &quot;Texans&quot;, &quot;Eagles&quot;, &quot;Dolphins&quot;, &quot;Packers&quot;, &quot;Colts&quot;, &quot;Be...
## $ home        &lt;chr&gt; &quot;Chiefs&quot;, &quot;Redskins&quot;, &quot;Patriots&quot;, &quot;Vikings&quot;, &quot;Jaguars&quot;,...
## $ forecast    &lt;chr&gt; &quot;58f Overcast&quot;, &quot;76f Partly Cloudy&quot;, &quot;73f Clear&quot;, &quot;DOME...
## $ wind        &lt;dbl&gt; 6, 4, 6, 2, 8, 11, 3, 12, 5, 3, 4, 6, 10, 7, 10, 7
## $ season      &lt;chr&gt; &quot;2020&quot;, &quot;2020&quot;, &quot;2020&quot;, &quot;2020&quot;, &quot;2020&quot;, &quot;2020&quot;, &quot;2020&quot;,...
## $ week        &lt;chr&gt; &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, ...
## $ temperature &lt;chr&gt; &quot;58&quot;, &quot;76&quot;, &quot;73&quot;, &quot;71&quot;, &quot;86&quot;, &quot;71&quot;, &quot;79&quot;, &quot;65&quot;, &quot;75&quot;, &quot;...
## $ weather     &lt;chr&gt; &quot;Overcast&quot;, &quot;Cloudy&quot;, &quot;Clear&quot;, &quot;DOME&quot;, &quot;Cloudy&quot;, &quot;DOME&quot;...</code></pre>
</div>
<div id="pivot-action" class="section level2">
<h2>Pivot Action</h2>
<p>At this point, the data is tidy’d enough to start using. However, before we move on to writing a function to scrape the data for us across multiple web pages at a time, we need to alter the orientation of the data. As is, there is a row for each game. Thinking bigger picture, we will want a row for each team - so that each row is unique for season, week, and team. Suppose you want to join or merge this weather data with a team’s box score data from one or multiple games? This final transformation will make that task much easier.</p>
<p>With the <code>pivot_longer()</code> function, we can elongate the data using the home and away columns - renaming the pivoted values column simply to ‘team’. For example, if the Texans and Chiefs played, this function ensures there is a row for each team along with the corresponding weather data from the remaining columns. What you’ll notice is that instead of 16 rows like the previous outputs, there will now be 32 (1 for each team instead of 1 for each game). The result is a clean dataset with a row for each season, week, team.</p>
<pre class="r"><code>url %&gt;% 
  read_html() %&gt;% 
  html_table() %&gt;%
  .[[1]] %&gt;% 
  clean_names() %&gt;%
  select(away, home, forecast, wind) %&gt;%
  mutate(season = str_sub(url, start= 31, end = 34),
         week = str_sub(gsub(&#39;.*\\-&#39;, &#39;&#39;, url), start = -3, end = -2),
         wind = as.numeric(gsub( &quot;m.*$&quot;, &quot;&quot;,wind)),
         temperature = ifelse(forecast == &#39;DOME&#39;, 71, gsub( &quot;f.*$&quot;, &quot;&quot;, forecast)),
         weather = gsub(&quot;.*? &quot;, &quot;&quot;, forecast)) %&gt;%
  pivot_longer(cols = c(&#39;away&#39;, &#39;home&#39;), values_to = &#39;team&#39;) %&gt;% 
  select(-name, -forecast) %&gt;% 
  select(team, season, week, temperature, wind, weather) %&gt;% 
  glimpse()</code></pre>
<pre><code>## Rows: 32
## Columns: 6
## $ team        &lt;chr&gt; &quot;Texans&quot;, &quot;Chiefs&quot;, &quot;Eagles&quot;, &quot;Redskins&quot;, &quot;Dolphins&quot;, &quot;...
## $ season      &lt;chr&gt; &quot;2020&quot;, &quot;2020&quot;, &quot;2020&quot;, &quot;2020&quot;, &quot;2020&quot;, &quot;2020&quot;, &quot;2020&quot;,...
## $ week        &lt;chr&gt; &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, ...
## $ temperature &lt;chr&gt; &quot;58&quot;, &quot;58&quot;, &quot;76&quot;, &quot;76&quot;, &quot;73&quot;, &quot;73&quot;, &quot;71&quot;, &quot;71&quot;, &quot;86&quot;, &quot;...
## $ wind        &lt;dbl&gt; 6, 6, 4, 4, 6, 6, 2, 2, 8, 8, 11, 11, 3, 3, 12, 12, 5, ...
## $ weather     &lt;chr&gt; &quot;Overcast&quot;, &quot;Overcast&quot;, &quot;Cloudy&quot;, &quot;Cloudy&quot;, &quot;Clear&quot;, &quot;C...</code></pre>
</div>
</div>
<div id="mapping-the-function" class="section level1">
<h1>Mapping the Function</h1>
<p>The final objective here is to use this code as a function. Functions can be used over and over without rewriting code. In this example, we can use and reuse our code for existing urls, grabbing data from a particular week of a particular season - or we can run for all weeks from multiple seasons. For this blog post, we’re going to grab weather data for weeks 1 through 17 from 2018 and 2019.</p>
<p>We actually need two functions. One for generating the web page urls and another for scraping / wrangling the data. For generating the urls, we establish the sequence of weeks and years. Then, with the help of <code>tidyr</code> and the <code>crossing()</code> function, we can generate all combinations of weeks and years. The result is a tibble with two columns containing a row for weeks 1-17 for each season 2018 and 2019. The function that generates the urls simply concatenates the base url with the year and week provided. Using <code>pmap</code>, we can iterate over each row of the <code>weather_weeks_and_years</code> tibble, passing the year and week from each row into our <code>generate_urls</code> function. The result is a list of 85 urls or web pages that we can now scrape data from.</p>
<pre class="r"><code># set up weeks and years
weeks &lt;- c(1:17)
years &lt;- c(2018:2019)
weather_weeks_and_years &lt;- crossing(year = years, week = weeks) # generate all unique combinations

# function to generate urls
generate_urls &lt;- function(year, week) {
  full_url &lt;- glue::glue(&quot;http://nflweather.com/en/week/{year}/week-{week}/&quot;)
}

# pass weeks and years through function
url_list &lt;- pmap(weather_weeks_and_years, generate_urls)

head(url_list)</code></pre>
<pre><code>## [[1]]
## http://nflweather.com/en/week/2018/week-1/
## 
## [[2]]
## http://nflweather.com/en/week/2018/week-2/
## 
## [[3]]
## http://nflweather.com/en/week/2018/week-3/
## 
## [[4]]
## http://nflweather.com/en/week/2018/week-4/
## 
## [[5]]
## http://nflweather.com/en/week/2018/week-5/
## 
## [[6]]
## http://nflweather.com/en/week/2018/week-6/</code></pre>
<p>Below, we create a function that accepts a url, scrapes, wrangles, and returns the data. The code is the same code written above, used repeatedly for each url. We execute the function for each url within <code>url_list</code> by using <code>map_df</code> from the <code>purrr</code> package. <code>map_df</code> accepts an input list and applies a function to each element while returning a data frame. It might take a minute or two to run. Upon completion, you should have a solid weather dataset to start digging into.</p>
<pre class="r"><code># function to scrape weather
scrape_weather_data &lt;- function(webpage_url) {
  webpage_url %&gt;% 
    read_html() %&gt;% 
    html_table() %&gt;%
    .[[1]] %&gt;% 
    clean_names() %&gt;%
    select(away, home, forecast, wind) %&gt;%
    mutate(season = str_sub(webpage_url, start= 31, end = 34),
           week = str_sub(gsub(&#39;.*\\-&#39;, &#39;&#39;, webpage_url), start = -3, end = -2),
           wind = as.numeric(gsub( &quot;m.*$&quot;, &quot;&quot;,wind)),
           temperature = ifelse(forecast == &#39;DOME&#39;, 71, gsub( &quot;f.*$&quot;, &quot;&quot;, forecast)),
           weather = gsub(&quot;.*? &quot;, &quot;&quot;, forecast)) %&gt;%
    pivot_longer(cols = c(&#39;away&#39;, &#39;home&#39;), values_to = &#39;team&#39;) %&gt;% 
    select(-name, -forecast) %&gt;% 
    select(team, season, week, temperature, wind, weather)
}

# pass urls through the function
weather_data &lt;- map_df(url_list, scrape_weather_data)

glimpse(weather_data)</code></pre>
<pre><code>## Rows: 1,024
## Columns: 6
## $ team        &lt;chr&gt; &quot;Falcons&quot;, &quot;Eagles&quot;, &quot;Bills&quot;, &quot;Ravens&quot;, &quot;Jaguars&quot;, &quot;Gia...
## $ season      &lt;chr&gt; &quot;2018&quot;, &quot;2018&quot;, &quot;2018&quot;, &quot;2018&quot;, &quot;2018&quot;, &quot;2018&quot;, &quot;2018&quot;,...
## $ week        &lt;chr&gt; &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, ...
## $ temperature &lt;chr&gt; &quot;81&quot;, &quot;81&quot;, &quot;62&quot;, &quot;62&quot;, &quot;58&quot;, &quot;58&quot;, &quot;71&quot;, &quot;71&quot;, &quot;62&quot;, &quot;...
## $ wind        &lt;dbl&gt; 2, 2, 11, 11, 4, 4, 1, 1, 6, 6, 9, 9, 4, 4, 9, 9, 4, 4,...
## $ weather     &lt;chr&gt; &quot;Rain&quot;, &quot;Rain&quot;, &quot;Rain&quot;, &quot;Rain&quot;, &quot;Rain&quot;, &quot;Rain&quot;, &quot;DOME&quot;,...</code></pre>
</div>
<div id="finally" class="section level1">
<h1>Finally</h1>
<p>That was a lot. From regular expressions, to creating functions, and using <code>purrr</code> - there were quite a few different tasks described in this post. In the wild, most data are messy and need to be gathered / cleaned using a wide variety of tricks and trades. Good bye.</p>
</div>
